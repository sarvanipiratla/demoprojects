{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Road_lane_detection_sp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN6qPppYJsFQ23szdvnIuXh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarvanipiratla/demoprojects/blob/main/Road_lane_detection_sp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwZFx3x907QX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np \n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "#import os\n",
        "#import matplotlib.image as mpimg\n",
        "#from moviepy.editor import VideoFileClip\n",
        "#import math"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1IJjVOL9Fzy"
      },
      "source": [
        "def canny_edge_detector (image): \n",
        "\n",
        "    #Convert the image color to grayscale\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    #Reduce noise from the image\n",
        "    blur = cv2.GaussianBlur(gray_image, (5,5), 0)\n",
        "    canny = cv2.Canny(blur, 50, 150)\n",
        "    return canny"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq1hslQV3Aid"
      },
      "source": [
        "# Apply frame masking and find region of interest:\n",
        "def region_of_interest(image):\n",
        "    height = image.shape[0]\n",
        "    polygons = np.array([[(200, height), (1100, height), (550,250)]])\n",
        "    \n",
        "    mask = np.zeros_like(image)\n",
        "\n",
        "    #Fill poly-function deals with multiple polygon\n",
        "    cv2.fillPoly(mask, polygons, 255)\n",
        "\n",
        "    #Bitwise operation between canny image and mask image\n",
        "    masked_image = cv2.bitwise_and(image, mask)\n",
        "    return masked_image"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_dtf0-H-hzQ"
      },
      "source": [
        "#We are going to find the coordinates of our road lane: \n",
        "\n",
        "def create_coordinates(image, line_parameters):\n",
        "    slope, intercept = line_parameters\n",
        "    y1 = image.shape[0]\n",
        "    y2 = int(y1*(3/5))\n",
        "    x1 = int((y1 - intercept)/slope)\n",
        "    x2 = int((y2 - intercept)/slope)\n",
        "    return np.array([x1, y1, x2, y2])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkiDGCRJ_T0E"
      },
      "source": [
        "#Differentiating left and right road lanes with the help of positive and negative slopes\n",
        "#respectively and appending them into the lists, if the slope is negative then the road lane belongs \n",
        "# to the left hand side of the vehicle, and if the slope is positive then the road\n",
        "#lane belongs to the right hand side of the vehicle \n",
        "\n",
        "def average_slope_intercept(image, lines):\n",
        "    left_fit = []\n",
        "    right_fit = []\n",
        "    for line in lines:\n",
        "        x1, y1, x2, y2 = line.reshape(4)\n",
        "\n",
        "        #It will fit the polynomial and the intercept and \n",
        "        parameters = np.polyfit ((x1,x2), (y1, y2), 1)\n",
        "        slope = parameters[0]\n",
        "        intercept = parameters[1]\n",
        "        if slope < 0:\n",
        "            left_fit.append((slope, intercept))\n",
        "        else: \n",
        "            right_fit.append((slope, intercept))\n",
        "\n",
        "    left_fit_average = np.average(left_fit, axis = 0)\n",
        "    right_fit_average = np.average(right_fit, axis = 0)\n",
        "    left_line = create_coordinates(image, left_fit_average)\n",
        "    right_line = create_coordinates(image, right_fit_average)\n",
        "    return np.array([left_line, right_line])\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5d5bHy3A6Zg"
      },
      "source": [
        "#Fitting the coordinates into our actual image and then returning the image\n",
        "#with the detected line (road with the detected lane):\n",
        "\n",
        "def display_lines(image, lines):\n",
        "    line_image = np.zeros_like(image)\n",
        "    if lines is not None:\n",
        "        for x1, y1, x2, y2 in lines:\n",
        "            cv2.line(line_image, (x1, y1), (x2, y2), (255,0, 0), 10)\n",
        "    return line_image"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgJekD-16Mjo"
      },
      "source": [
        "#Firstly, the video file is read and decoded into frames and using \n",
        "#Houghline method the straightline which is going through the image is \n",
        "#detected. Then we call all the functions\n",
        "\n",
        "#Path of dataset director\n",
        "cap = cv2.VideoCapture(\"/content/test2.mp4\")\n",
        "while(cap.isOpened()):\n",
        "    _, frame = cap.read()\n",
        "    canny_image = canny_edge_detector(frame)\n",
        "    cropped_image = region_of_interest(canny_image)\n",
        "\n",
        "    lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength = 40, maxLineGap = 5)\n",
        "\n",
        "    averaged_lines = average_slope_intercept(frame, lines)\n",
        "    line_image = display_lines(frame, averaged_lines)\n",
        "    combo_image = cv2.addWeighted(frame, 0.8, line_image, 1, 1)\n",
        "    cv2_imshow(combo_image)\n",
        "\n",
        "# When the below two will be true and will press the 'q' on our \n",
        "# keyboard, we will break out from the loop\n",
        "\n",
        "## wait 0 will wait for infinitely between each frames. \n",
        "# 1ms will wait for the specified time only between each frames\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "#close the video file\n",
        "cap.release()\n",
        "\n",
        "#destroy all the windows that is currently on\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNtLgZQ_8tbY"
      },
      "source": [
        "\n",
        "        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}